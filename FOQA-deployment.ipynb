{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[AZURE ML PRODUCTION DEPLOYMENT - FOQA DECISION TREE MODEL](https://c3.ndc.nasa.gov/dashlink/resources/1018/)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Packages installation - AML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38/bin//python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall scikit-learn\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall -U imbalanced-learn\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azureml\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azure-ai-ml\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azureml-inference-server-http\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azure-ai-formrecognizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Init Azure Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "subscription_id = '<insert-subscription-id>'\n",
        "resource_group = '<insert-resource-group>'\n",
        "workspace_name = '<insert-workspace-name>'\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore Azure Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='foqa-data-asset')\n",
        "dataset.download(target_path='.', overwrite=True)\n",
        "# Download mounts the file as local file\n",
        "# TODO: How to work directly without mounting\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "with dataset.mount() as mount_context:\n",
        "    # print(os.listdir(mount_context.mount_point)[0])\n",
        "    full_data = np.load(os.listdir(mount_context.mount_point)[0])\n",
        "\n",
        "data = full_data['data']\n",
        "label = full_data['label']\n",
        "print(\"Data:\",data.shape)\n",
        "print(\"Label:\",label.shape)'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Create training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "    pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Create custom environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./conda.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./conda.yaml\n",
        "name: foqa-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - scikit-learn\n",
        "  - pandas\n",
        "  - numpy\n",
        "  - matplotlib\n",
        "  - xgboost\n",
        "  - imbalanced-learn  \n",
        "  - pip\n",
        "  - pip:\n",
        "    - azureml\n",
        "    - azure-ai-ml\n",
        "    - azureml-mlflow\n",
        "    - azureml-inference-server-http"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'foqa-env', 'description': 'Environment for FOQA', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourceGroups/foqa-resource-2/providers/Microsoft.MachineLearningServices/workspaces/foqa-ws-2/environments/foqa-env/versions/3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/foqa-compute/code/Users/duc.tran', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5574109d30>, 'serialize': <msrest.serialization.Serializer object at 0x7f5574109e80>, 'version': '3', 'latest_version': None, 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.7', 'scikit-learn', 'pandas', 'numpy', 'matplotlib', 'xgboost', 'imbalanced-learn', 'pip', {'pip': ['azureml', 'azure-ai-ml', 'azureml-mlflow', 'azureml-inference-server-http']}], 'name': 'foqa-env'}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.7\",\\n    \"scikit-learn\",\\n    \"pandas\",\\n    \"numpy\",\\n    \"matplotlib\",\\n    \"xgboost\",\\n    \"imbalanced-learn\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"azureml\",\\n        \"azure-ai-ml\",\\n        \"azureml-mlflow\",\\n        \"azureml-inference-server-http\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"foqa-env\"\\n}'})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    conda_file=\"./conda.yaml\",\n",
        "    name=\"foqa-env\",\n",
        "    description=\"Environment for FOQA\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Create compute cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure Machine Learning Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=1,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "    print(\n",
        "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
        "    )\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Submit the model training as a job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "NOTE:\n",
        "1. How to get \"path\" arg for command\n",
        "    1.1:\n",
        "        # all_data_assets = ml_client.data.list()\n",
        "        # data_asset_path = ml_client.data.get(name=\"foqa-data-asset\", version=\"1\")\n",
        "        # Copy the path\n",
        "    1.2:\n",
        "        # to get the below path: AML -> Data -> Datastore -> <datastore-name> -> Browse -> <Click on triple dot of target file> -> Copy URI\n",
        "\n",
        "2. List all available \"environment\" arg for command:\n",
        "    # Portal -> cloud shell -> az ml environment list --resource-group foqa-resource --workspace-name foqa-ws\n",
        "'''\n",
        "\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "\n",
        "registered_model_name = \"foqa_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"azureml://subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourcegroups/foqa-resource-2/workspaces/foqa-ws-2/datastores/foqa_datastore/paths/DASHlink_full_fourclass_raw_comp.npz\",\n",
        "        ),\n",
        "        train_test_ratio=0.2,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --train_test_ratio ${{inputs.train_test_ratio}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"foqa-env@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    display_name=\"foqa-prediction\",\n",
        ")\n",
        "\n",
        "returned_job = ml_client.create_or_update(job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Register Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "job_name = returned_job.name\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\", \n",
        "    name=\"foqa-model\",\n",
        "    description=\"Model for FOQA\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
