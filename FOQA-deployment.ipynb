{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[AZURE ML PRODUCTION DEPLOYMENT - FOQA DECISION TREE MODEL](https://c3.ndc.nasa.gov/dashlink/resources/1018/)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Packages installation - AML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38/bin//python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall scikit-learn\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall -U imbalanced-learn\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azureml\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azure-ai-ml\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azureml-inference-server-http\n",
        "!/anaconda/envs/azureml_py38/bin/python -m pip install --upgrade --force-reinstall azure-ai-formrecognizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Init Azure Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "\n",
        "subscription_id = 'e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216'\n",
        "resource_group = 'foqa-resource-2'\n",
        "workspace_name = 'foqa-ws-2'\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore Azure Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='foqa-data-asset')\n",
        "dataset.download(target_path='.', overwrite=True)\n",
        "# Download mounts the file as local file\n",
        "# TODO: How to work directly without mounting\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "with dataset.mount() as mount_context:\n",
        "    # print(os.listdir(mount_context.mount_point)[0])\n",
        "    full_data = np.load(os.listdir(mount_context.mount_point)[0])\n",
        "\n",
        "data = full_data['data']\n",
        "label = full_data['label']\n",
        "print(\"Data:\",data.shape)\n",
        "print(\"Label:\",label.shape)'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Create training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "import numpy as np\n",
        "import xgboost\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix,ConfusionMatrixDisplay\n",
        "\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        "    # input and output arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        "    parser.add_argument(\"--train_test_ratio\", type=float, required=False, default=0.20)\n",
        "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Start Logging\n",
        "    mlflow.start_run()\n",
        "\n",
        "    # enable autologging\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # Load data\n",
        "    full_data = np.load(args.data)\n",
        "    data = full_data['data']\n",
        "    label = full_data['label']\n",
        "\n",
        "    # Reduce timestep dimension\n",
        "    data = np.average(data, axis=1)\n",
        "\n",
        "    # Oversampling using ADASYN\n",
        "    oversample = ADASYN()\n",
        "    data, label = oversample.fit_resample(data, label)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=args.train_test_ratio)\n",
        "\n",
        "    # Train the model\n",
        "    model = xgboost.XGBClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Measuring performance - accuracy score\n",
        "    preds = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "\n",
        "    # Measuring performance - ROC AUC score\n",
        "    probs = model.predict_proba(X_test)\n",
        "    roc_auc = roc_auc_score(y_test, probs, multi_class='ovr')\n",
        "\n",
        "    print(\"Accuracy: %.2f%% \\nROC AUC Score: %.2f%%\" % (accuracy * 100.0,roc_auc * 100))\n",
        "\n",
        "    # Registering the model to the workspace\n",
        "    print(\"Registering the model via MLFlow\")\n",
        "\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=model,\n",
        "        registered_model_name=args.registered_model_name,\n",
        "        artifact_path=args.registered_model_name,\n",
        "    )\n",
        "\n",
        "    # Saving the model to a file\n",
        "    mlflow.sklearn.save_model(\n",
        "        sk_model=model,\n",
        "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
        "    )\n",
        "\n",
        "    # Stop Logging\n",
        "    mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Create custom environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./conda.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./conda.yaml\n",
        "name: foqa-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.7\n",
        "  - scikit-learn\n",
        "  - pandas\n",
        "  - numpy\n",
        "  - matplotlib\n",
        "  - xgboost\n",
        "  - imbalanced-learn  \n",
        "  - pip\n",
        "  - pip:\n",
        "    - azureml\n",
        "    - azure-ai-ml\n",
        "    - azureml-mlflow\n",
        "    - azureml-inference-server-http"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'foqa-env', 'description': 'Environment for FOQA', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourceGroups/foqa-resource-2/providers/Microsoft.MachineLearningServices/workspaces/foqa-ws-2/environments/foqa-env/versions/3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/foqa-compute/code/Users/duc.tran', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5574109d30>, 'serialize': <msrest.serialization.Serializer object at 0x7f5574109e80>, 'version': '3', 'latest_version': None, 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.7', 'scikit-learn', 'pandas', 'numpy', 'matplotlib', 'xgboost', 'imbalanced-learn', 'pip', {'pip': ['azureml', 'azure-ai-ml', 'azureml-mlflow', 'azureml-inference-server-http']}], 'name': 'foqa-env'}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.7\",\\n    \"scikit-learn\",\\n    \"pandas\",\\n    \"numpy\",\\n    \"matplotlib\",\\n    \"xgboost\",\\n    \"imbalanced-learn\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"azureml\",\\n        \"azure-ai-ml\",\\n        \"azureml-mlflow\",\\n        \"azureml-inference-server-http\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"foqa-env\"\\n}'})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    conda_file=\"./conda.yaml\",\n",
        "    name=\"foqa-env\",\n",
        "    description=\"Environment for FOQA\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Create compute cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure Machine Learning compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure Machine Learning Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=1,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "    print(\n",
        "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
        "    )\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Submit the model training as a job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "NOTE:\n",
        "1. How to get \"path\" arg for command\n",
        "    1.1:\n",
        "        # all_data_assets = ml_client.data.list()\n",
        "        # data_asset_path = ml_client.data.get(name=\"foqa-data-asset\", version=\"1\")\n",
        "        # Copy the path\n",
        "    1.2:\n",
        "        # to get the below path: AML -> Data -> Datastore -> <datastore-name> -> Browse -> <Click on triple dot of target file> -> Copy URI\n",
        "\n",
        "2. List all available \"environment\" arg for command:\n",
        "    # Portal -> cloud shell -> az ml environment list --resource-group foqa-resource --workspace-name foqa-ws\n",
        "'''\n",
        "\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "\n",
        "registered_model_name = \"foqa_model\"\n",
        "\n",
        "job = command(\n",
        "    inputs=dict(\n",
        "        data=Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"azureml://subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourcegroups/foqa-resource-2/workspaces/foqa-ws-2/datastores/foqa_datastore/paths/DASHlink_full_fourclass_raw_comp.npz\",\n",
        "        ),\n",
        "        train_test_ratio=0.2,\n",
        "        registered_model_name=registered_model_name,\n",
        "    ),\n",
        "    code=\"./src/\",  # location of source code\n",
        "    command=\"python main.py --data ${{inputs.data}} --train_test_ratio ${{inputs.train_test_ratio}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
        "    environment=\"foqa-env@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    display_name=\"foqa-prediction\",\n",
        ")\n",
        "\n",
        "returned_job = ml_client.create_or_update(job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Register Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "job_name = returned_job.name\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\", \n",
        "    name=\"foqa-model\",\n",
        "    description=\"XGBoost Model for FOQA\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Deploy the model "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.1 Create scoring script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./src/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./src/score.py\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "\n",
        "def init():\n",
        "    \"\"\"\n",
        "    This function is called when the container is initialized/started, typically after create/update of the deployment.\n",
        "    You can write the logic here to perform init operations like caching the model in memory\n",
        "    \"\"\"\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # Please provide your model's folder name if there is one\n",
        "    # <model-name>/model.pkl\n",
        "    model_path = os.path.join(\n",
        "        os.getenv(\"AZUREML_MODEL_DIR\"), \"foqa_model/model.pkl\"\n",
        "    )\n",
        "    # deserialize the model file back into a sklearn model\n",
        "    model = joblib.load(model_path)\n",
        "    logging.info(\"Init complete\")\n",
        "\n",
        "\n",
        "def run(raw_data):\n",
        "    \"\"\"\n",
        "    This function is called for every invocation of the endpoint to perform the actual scoring/prediction.\n",
        "    In the example we extract the data from the json input and call the scikit-learn model's predict()\n",
        "    method and return the result back\n",
        "    \"\"\"\n",
        "    logging.debug(\"model 1: request received\")\n",
        "    data = json.loads(raw_data)\n",
        "    data = data[\"data\"]\n",
        "    data = np.array(data)\n",
        "    data = np.average(data, axis=1)\n",
        "    result = model.predict(data)\n",
        "    logging.info(\"Request processed\")\n",
        "    return result.tolist()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.2 Create an Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint foqa-endpoint-4dd696a7 provisioning state: Succeeded\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        ")\n",
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "foqa_endpoint_name = \"foqa-endpoint-\" + str(uuid.uuid4())[:8]\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=foqa_endpoint_name,\n",
        "    description=\"Endpoint for FOQA\",\n",
        "    auth_mode=\"key\",\n",
        ")\n",
        "\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.3 Local verification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3.1 Install the packages locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local Deployment packages installation\n",
        "'''\n",
        "!/usr/local/bin/python3.10 -m pip install azureml\n",
        "!/usr/local/bin/python3.10 -m pip install azure-ai-ml\n",
        "!/usr/local/bin/python3.10 -m pip install azureml-inference-server-http\n",
        "!/usr/local/bin/python3.10 -m pip install azure-identity\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3.2 Deploy locally "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration, Environment, Model\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=\"foqa-endpoint-defeffd5\",\n",
        "    model=Model(path=\"./model/model.pkl\"), # Need to download model artifacts\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "        conda_file=\"./conda.yaml\",\n",
        "        name=\"local-env\",\n",
        "        description=\"local Environment for FOQA\",\n",
        "    ),\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.online_deployments.begin_create_or_update(\n",
        "    deployment, local=True, vscode_debug=True\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3.3 Debug local endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auth_mode: key\n",
            "location: local\n",
            "mirror_traffic: {}\n",
            "name: foqa-endpoint-defeffd5\n",
            "properties: {}\n",
            "provisioning_state: Succeeded\n",
            "scoring_uri: http://localhost:5001/score\n",
            "tags: {}\n",
            "traffic: {}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "endpoint_name = \"foqa-endpoint-defeffd5\"\n",
        "endpoint = ml_client.online_endpoints.get(name=endpoint_name, local=True)\n",
        "print(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3.4 Send test data & receive prediction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8.3.4.1 Create request.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finish the following code\n",
        "\n",
        "# %%writefile ./sample-request.json\n",
        "# TODO: Load data to X_test & modify the test_json\n",
        "# import json\n",
        "# test_json = np.ndarray.tolist(X_test[:10])\n",
        "# json_object = json.dumps(test_json)\n",
        "\n",
        "# # Writing to sample-request.json\n",
        "# with open(\"sample-request.json\", \"w\") as outfile:\n",
        "#     outfile.write('{\"data\":')\n",
        "#     outfile.write(json_object)\n",
        "#     outfile.write(\"}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8.3.4.2 Invoking the local endpoint with sample-request.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "endpoint_name = \"foqa-endpoint-defeffd5\"\n",
        "request_file_path = \"./sample-request.json\"\n",
        "\n",
        "ml_client.online_endpoints.invoke(endpoint_name=endpoint_name, request_file=request_file_path, local=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 8.4 ONLINE DEPLOYMENT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4.1 Configure Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of available instance types\n",
        "# https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?view=azureml-api-2\n",
        "\n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
        "\n",
        "foqa_endpoint_name = endpoint.name\n",
        "\n",
        "foqa_model = ml_client.models.get(name='foqa_model',version='1')\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=foqa_endpoint_name,\n",
        "    model=foqa_model,\n",
        "    environment=\"foqa-env@latest\",\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    # instance_type=\"Standard_DS3_v3\",\n",
        "    instance_type=\"Standard_F4s_v2\",\n",
        "    instance_count=3,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4.2 Deploy to Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint foqa-endpoint-4dd696a7 exists\n",
            "\u001b[32mUploading src (0.0 MBs): 100%|██████████| 3898/3898 [00:00<00:00, 93337.12it/s]\n",
            "\u001b[39m\n",
            "\n",
            "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "......................................................................."
          ]
        }
      ],
      "source": [
        "result = ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4.3 Direct traffic to endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
            "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://foqa-endpoint-4dd696a7.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://foqa-endpoint-4dd696a7.eastus2.inference.ml.azure.com/swagger.json', 'name': 'foqa-endpoint-4dd696a7', 'description': 'Endpoint for FOQA', 'tags': {}, 'properties': {'azureml.onlineendpointid': '/subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourcegroups/foqa-resource-2/providers/microsoft.machinelearningservices/workspaces/foqa-ws-2/onlineendpoints/foqa-endpoint-4dd696a7', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:7f2f69c2-5aa1-4ade-9e51-d64ace308061:ba660499-4389-4aad-8819-f28e1892de19?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/e3fb51e5-d8bd-4bf8-9685-bda3d5d2e216/resourceGroups/foqa-resource-2/providers/Microsoft.MachineLearningServices/workspaces/foqa-ws-2/onlineEndpoints/foqa-endpoint-4dd696a7', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/foqa-compute/code/Users/duc.tran', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f5554b927f0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f5554b92c40>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4.4 Test Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finish the following code\n",
        "\n",
        "# %%writefile {deploy_dir}/sample-request.json\n",
        "# TODO: Load data to X_test & modify the test_json\n",
        "# import json\n",
        "# test_json = np.ndarray.tolist(X_test[:10])\n",
        "# json_object = json.dumps(test_json)\n",
        "\n",
        "# # Writing to sample-request.json\n",
        "# with open(\"sample-request.json\", \"w\") as outfile:\n",
        "#     outfile.write('{\"data\":')\n",
        "#     outfile.write(json_object)\n",
        "#     outfile.write(\"}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[0, 0, 0, 1, 1, 0, 1, 0, 0, 0]'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=foqa_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
